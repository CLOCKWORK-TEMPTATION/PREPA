# بنية المشروع

## تنظيم الدليل

### الهيكل العام
```
e:\PREPA/
├── .agent/rules/                    # قواعد الوكيل المساعد
├── .amazonq/rules/                  # قواعد Amazon Q وبنك الذاكرة
├── .kiro/specs/                     # مواصفات مشروع الراوي
├── dataset_output/                  # مخرجات مجموعات البيانات الرئيسية
├── Extracted_Dataset/               # البيانات المستخرجة والمعالجة
├── docling_*.py                     # وحدات معالجة المستندات
├── screenplay_*.py                  # وحدات تحليل السيناريوهات
├── script_dataset_builder.py       # بناء مجموعات البيانات
└── txt_to_pdf_converter.py         # تحويل النصوص إلى PDF
```

### الدلائل الأساسية

#### دلائل التكوين والقواعد
- **.agent/rules/**: قواعد سلوك الوكيل المساعد
- **.amazonq/rules/**: قواعد Amazon Q وبنك الذاكرة للمشروع
- **.kiro/specs/**: مواصفات مشروع الراوي الإصدار الرابع

#### دلائل البيانات والمخرجات
- **dataset_output/**: المخرجات الرئيسية لمجموعات البيانات
  - `dialogue_turns.csv`: حوارات مستخرجة بتنسيق CSV
  - `gemini_analysis_report.json`: تقارير تحليل Gemini AI
  - `rag_dataset.jsonl`: بيانات RAG بتنسيق JSONL
  - `train_alpaca_contextual.json`: بيانات تدريب بتنسيق Alpaca
  - `train_sharegpt.json`: بيانات تدريب بتنسيق ShareGPT

- **Extracted_Dataset/**: البيانات المستخرجة والمعالجة
  - `dataset_output/`: مخرجات معالجة البيانات الأساسية
  - `docling_dataset_output/`: مخرجات معالجة Docling
  - `pddf/`: ملفات PDF المحولة (1-10.pdf)
  - ملفات نصية مرقمة (1-10.txt)

## المكونات الأساسية

### وحدات معالجة المستندات (Docling)

#### الاختبارات والعروض التوضيحية
- **docling_comprehensive_test.py**: اختبار شامل لجميع ميزات Docling
- **docling_basic_example.py**: أمثلة أساسية لاستخدام Docling
- **docling_simple_test.py**: اختبارات بسيطة للوظائف الأساسية
- **docling_final_demo.py**: العرض التوضيحي النهائي الكامل

#### تحسينات الأداء
- **docling_cpu_final.py**: معالجة محسّنة لوحدة المعالجة المركزية
- **docling_gpu_test.py**: اختبار تسريع GPU
- **docling_simple_cpu.py**: معالجة CPU مبسطة

#### الدعم متعدد اللغات
- **docling_arabic_rtl_test.py**: اختبار دعم اللغة العربية وRTL
- **arabic_output.md**: نتائج معالجة النصوص العربية

#### خطوط الأنابيب المتقدمة
- **docling_full_pipeline.py**: خط أنابيب معالجة كامل ومتكامل
- **docling_script_dataset_builder.py**: بناء مجموعات البيانات من السكريبت

### وحدات تحليل السيناريوهات

#### المعالجة الأساسية
- **screenplay_to_dataset.py**: تحويل السيناريوهات إلى مجموعات بيانات
- **screenplay_to_dataset1.py**: إصدار محدث من محول السيناريوهات

#### بناء البيانات
- **script_dataset_builder.py**: بناء مجموعات بيانات من السكريبت

### أدوات التحويل والمساعدة

#### تحويل التنسيقات
- **txt_to_pdf_converter.py**: تحويل ملفات النص إلى PDF

#### ملفات السجلات والتتبع
- **conversion.log**: سجل عمليات التحويل
- **dataset_builder.log**: سجل بناء مجموعات البيانات
- **docling_dataset_builder.log**: سجل بناء بيانات Docling
- **screenplay_dataset.log**: سجل معالجة السيناريوهات

## الأنماط المعمارية

### نمط خط الأنابيب (Pipeline Pattern)

#### خط أنابيب معالجة المستندات
1. **تهيئة المحول**: إعداد DocumentConverter مع خيارات التكوين
2. **معالجة المصدر**: استرجاع المستندات من URLs أو ملفات محلية
3. **تنفيذ التحويل**: معالجة المستند مع معالجة الأخطاء
4. **التصدير متعدد التنسيقات**: إنشاء مخرجات Markdown وJSON
5. **التحليل والتقارير**: تحليل البنية ومقاييس الأداء

#### خط أنابيب تحليل السيناريوهات
1. **تحليل النص**: استخراج المشاهد والحوارات والشخصيات
2. **تحليل المشاعر**: تقييم الحالة العاطفية للحوارات
3. **تحليل الشخصيات**: تتبع تطور الشخصيات عبر النص
4. **تحليل الحبكة**: فهم البنية الدرامية والثيمات
5. **التصدير والتقارير**: إنتاج مجموعات بيانات وتقارير تحليلية

### نمط المحول (Converter Pattern)

#### محولات التنسيق
- **PDF إلى Markdown**: تحويل مع الحفاظ على التخطيط
- **PDF إلى JSON**: استخراج البيانات المنظمة
- **نص إلى PDF**: تحويل النصوص العادية إلى PDF
- **سيناريو إلى مجموعة بيانات**: استخراج البيانات التدريبية

### نمط المصنع (Factory Pattern)

#### مصانع المعالجة
- **DocumentConverter Factory**: إنشاء محولات مخصصة حسب نوع المستند
- **Dataset Exporter Factory**: إنشاء مصدرين مختلفين حسب التنسيق المطلوب
- **Analyzer Factory**: إنشاء محللين متخصصين (مشاعر، شخصيات، حبكة)

### نمط الاستراتيجية (Strategy Pattern)

#### استراتيجيات المعالجة
- **CPU Processing Strategy**: معالجة محسّنة لوحدة المعالجة المركزية
- **GPU Processing Strategy**: معالجة مسرّعة بالأجهزة
- **RTL Processing Strategy**: معالجة خاصة للنصوص من اليمين إلى اليسار

#### استراتيجيات التصدير
- **Alpaca Export Strategy**: تصدير بتنسيق Alpaca للتدريب
- **ShareGPT Export Strategy**: تصدير للمحادثات الطويلة
- **RAG Export Strategy**: تصدير لأنظمة البحث والاسترجاع

## العلاقات بين المكونات

### التكامل الأفقي
- **معالجة المستندات ← تحليل السيناريوهات**: استخدام Docling لاستخراج النصوص ثم تحليلها
- **تحليل المشاعر ← تطوير الشخصيات**: ربط التحليل العاطفي بتطور الشخصيات
- **استخراج البيانات ← بناء مجموعات البيانات**: تحويل البيانات المستخرجة إلى تنسيقات تدريب

### التكامل العمودي
- **طبقة المعالجة الأساسية**: Docling وأدوات التحويل الأساسية
- **طبقة التحليل المتقدم**: تحليل المشاعر والشخصيات والحبكة
- **طبقة التصدير والإنتاج**: تحويل النتائج إلى تنسيقات قابلة للاستخدام

### نقاط التكامل الخارجية
- **Google Gemini AI**: للتحليل المتقدم والذكي للمحتوى
- **arXiv Repository**: مصدر المستندات الأكاديمية للاختبار
- **تنسيقات التدريب القياسية**: Alpaca، ShareGPT، RAG

## إدارة التكوين والبيانات

### ملفات التكوين
- **.env**: متغيرات البيئة والمفاتيح السرية
- **قواعد السلوك**: في دلائل .agent و .amazonq

### إدارة البيانات
- **فصل المدخلات والمخرجات**: دلائل منفصلة للبيانات الخام والمعالجة
- **تنظيم حسب النوع**: تجميع الملفات حسب نوع المعالجة والتنسيق
- **تتبع الإصدارات**: ملفات سجلات مفصلة لتتبع العمليات